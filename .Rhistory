# website and assembles a nice data.frame
scrapeList <- function(year = 2014) {
cat('Assembling a list of documents.')
# list of urls
list_url = paste('http://www.who.int/csr/don/archive/year/', year, '/en/', sep="")
# getting the html
doc <- htmlParse(list_url)
cat('.')
# XPath to the PDF link only
output <- data.frame(
date =  xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/a', xmlValue),
url = xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/a', xmlGetAttr, "href"),
year = year)
cat('.')
# ISSUE
# apparently the name field is returning an extra name somewhere
# name = xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/span', xmlValue),
cat('.')
cat('done.')
# fixing URLs
output$url <- sub('/entity/', 'http://www.who.int/', output$url)
return(output)
}
updateList <- scrapeList()
VieW(updateList)
View(updateList)
# function that gets the list of documents from WHO
# website and assembles a nice data.frame
scrapeList <- function(year = 2014) {
cat('Assembling a list of documents.')
# list of urls
list_url = paste('http://www.who.int/csr/don/archive/year/', year, '/en/', sep="")
# getting the html
doc <- htmlParse(list_url)
cat('.')
# XPath to the PDF link only
output <- data.frame(
date =  xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/a', xmlValue),
url = xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/a', xmlGetAttr, "href"),
year = year)
cat('.')
# ISSUE
# apparently the name field is returning an extra name somewhere
# name = xpathSApply(doc, '//*[@id="content"]/div/div[1]/ul/li/span', xmlValue),
cat('.')
cat('done.')
# fixing URLs
output$url <- sub('/entity/', 'http://www.who.int/', output$url)
output$url <- sub('index.html', '', output$url)
return(output)
}
updateList <- scrapeList()
View(updateList)
View(updateList)
library(RCurl)
library(XML)
letters
class(letters)
for (i in 1:letters) {
print(toupper(letter[i]))
}
let <- as.list(letters)
let
for (i in 1:letters) {
print(toupper(let[i]))
}
for (i in 1:length(letters)) {
print(toupper(let[i]))
}
for (i in 1:length(letters)) {
print(toupper(letters[i]))
}
for (i in 1:length(letters)) {
print(toupper(letters[i]))
}
for (i in 1:length(letters)) {
query_url <- paste0(base_url, toupper(letters[i]))
}
base_url = "http://www.imsdb.com/alphabetical/"
for (i in 1:length(letters)) {
query_url <- paste0(base_url, toupper(letters[i]))
}
for (i in 1:length(letters)) {
query_url <- paste0(base_url, toupper(letters[i]))
print(paste0(base_url, toupper(letters[i])))
}
## Scraper for RNI Colombia's Website.
# dependencies
library(XML)
library(RCurl)
# function that gets the list of documents from WHO
# website and assembles a nice data.frame
scrapeList <- function(url) {
cat('----------------------------------------\n')
cat('Scraping data from RNI-Colombia website.\n')
cat('----------------------------------------\n')
# getting the html
doc <- htmlParse(url)
# getting only the right fields from the page
output <- data.frame(
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td[1]', xmlValue),
number_of_victims =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td[2]', xmlValue),
number_of_events = xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[2]/table/tbody/tr/td[2]', xmlValue)
)
# results
cat('-------------------------------\n')
cat('Done!\n')
cat('-------------------------------\n')
return(output)
}
updateList <- scrapeList('http://rni.unidadvictimas.gov.co/?q=node/107')
View(updateList)
updateList
url = 'http://rni.unidadvictimas.gov.co/?q=node/107'
url
doc <- htmlParse(url)
dc
doc
url
doc <- htmlParse(url)
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td[1]', xmlValue)
year
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td[1]', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr[2]/td[1]', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody', xmlValue)
xpathSApply(doc, '//*[@id="main"]', xmlValue)
# getting only the right fields from the page
output <- data.frame(
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/td[1]', xmlValue),
number_of_victims =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td[2]', xmlValue),
number_of_events = xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[2]/table/tbody/tr/td[2]', xmlValue)
)
View(output)
url = 'http://cifras.unidadvictimas.gov.co/Home/Vigencia_ocurrencia'
doc <- htmlParse(url)
# getting only the right fields from the page
output <- data.frame(
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/td[1]', xmlValue),
number_of_victims =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td[2]', xmlValue),
number_of_events = xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[2]/table/tbody/tr/td[2]', xmlValue)
)
View(output)
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/td[1]', xmlValue)
year
doc
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/td[1]', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr[2]/td[1]', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr[2]/td', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr[2]', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/td', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody/tr/td[1]', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tbody', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table')
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr')
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td')
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr[1]/td', xmlValue)
xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td[1]', xmlValue)
# getting only the right fields from the page
output <- data.frame(
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td[1]', xmlValue),
number_of_victims =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td[2]', xmlValue),
number_of_events = xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[2]/table/tr/td[2]', xmlValue)
)
View(output)
source('code/write_tables.R')
View(output)
output$number_of_victims <- gsub(".", "", output$number_of_victims)
output$number_of_events <- gsub(".", "", output$number_of_events)
View(output)
###################################################
###################################################
######### Scraping data from RNI's website ########
###################################################
###################################################
# function that gets the list of documents from WHO
# website and assembles a nice data.frame
scrapeList <- function(url) {
cat('----------------------------------------\n')
cat('Scraping data from RNI-Colombia website.\n')
cat('----------------------------------------\n')
# getting the html
doc <- htmlParse(url)
# getting only the right fields from the page
output <- data.frame(
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td[1]', xmlValue),
number_of_victims =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td[2]', xmlValue),
number_of_events = xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[2]/table/tr/td[2]', xmlValue)
)
# cleaning
output$number_of_victims <- gsub(".", "", output$number_of_victims)
output$number_of_events <- gsub(".", "", output$number_of_events)
# results
cat('-------------------------------\n')
cat('Done!\n')
cat('-------------------------------\n')
return(output)
}
# running the function
rniData <- scrapeList('http://cifras.unidadvictimas.gov.co/Home/Vigencia_ocurrencia')
View(rniData)
###################################################
###################################################
######### Scraping data from RNI's website ########
###################################################
###################################################
# function that gets the list of documents from WHO
# website and assembles a nice data.frame
scrapeList <- function(url) {
cat('----------------------------------------\n')
cat('Scraping data from RNI-Colombia website.\n')
cat('----------------------------------------\n')
# getting the html
doc <- htmlParse(url)
# getting only the right fields from the page
output <- data.frame(
year =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td[1]', xmlValue),
number_of_victims =  xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[1]/table/tr/td[2]', xmlValue),
number_of_events = xpathSApply(doc, '//*[@id="main"]/fieldset[2]/div[2]/table/tr/td[2]', xmlValue)
)
# cleaning
output$number_of_victims <- gsub("[.]", "", output$number_of_victims)
output$number_of_events <- gsub("[.]", "", output$number_of_events)
# results
cat('-------------------------------\n')
cat('Done!\n')
cat('-------------------------------\n')
return(output)
}
# running the function
rniData <- scrapeList('http://cifras.unidadvictimas.gov.co/Home/Vigencia_ocurrencia')
View(rniData)
library(XML)
library(RCurl)
library(rjson)
title =  xpathSApply(doc, '//item')
url = 'http://healthmap.org/rss/ebola-all.rss'
doc <- xmlInternalTreeParse(url)
title =  xpathSApply(doc, '//item')
title
xpathSApply(doc, '//item/category/@domain["location"]', xmlValue)
xpathSApply(doc, '//item/category/@domain["location"]')
xpathSApply(doc, '//item/category/@domain')
xpathSApply(doc, '//item/category/@domain[.["location"]')
xpathSApply(doc, '//item/category/@domain[.="location"]')
xpathSApply(doc, '//item/category/@domain[.="location"]', xmlValue)
xpathSApply(doc, '//item/category/@domain[.="location"]')
xpathSApply(doc, '//item/category')
xpathSApply(doc, '//item/category/domain')
xpathSApply(doc, '//item/category')
xpathSApply(doc, '//item/category/@domain')
xpathSApply(doc, '//item/category/@domain["location"]')
xpathSApply(doc, '//item/category/@domain[.="location"]')
xpathSApply(doc, '//item/category/@domain[.="location"]', xmlAttrs)
xpathSApply(doc, '//item/category/@domain', xmlAttrs)
xpathSApply(doc, '//item/category', xmlAttrs)
xpathSApply(doc, '//item/category/@domain')
xpathSApply(doc, '//item/category/', xmlValue)
xpathSApply(doc, '//item/category', xmlValue)
xpathSApply(doc, '//item/category', xmlValue)[2]
xpathSApply(doc, '//item/category', xmlValue)
xpathSApply(doc, '//item/category')
xpathSApply(doc, '//item/category', xmlValue)
xpathSApply(doc, '//item/category[not(@location)]', xmlValue)
xpathSApply(doc, '//item/category[not(@desease)]', xmlValue)
xpathSApply(doc, '//item/category[not(@desease)]')
xpathSApply(doc, '//item/category/domain[not(@disease)]')
xpathSApply(doc, '//item/category/domain')
xpathSApply(doc, '//item/category/@domain')
xpathSApply(doc, '//item/category/@domain',xmlValue)
xpathSApply(doc, '//item/category/@domain', xmlValue)
xpathSApply(doc, '//item/category/domain', xmlValue)
xpathSApply(doc, '//item/category')
xpathSApply(doc, '//item/category[@domain]')
xpathSApply(doc, '//item/category[@domain]/@location')
xpathSApply(doc, '//item/category[@domain]/location')
xpathSApply(doc, '//item/category[@domain="location"]')
xpathSApply(doc, '//item/category[@domain="location"]', xmlValue)
# Function that fetches the data available
# in HealthMap's website and transforms
# the results into a data table.
scrapeHealthMap <- function() {
cat('----------------------------------------\n')
cat("Collecting the table from HealthMap.\n")
cat('----------------------------------------\n')
# HealthMap RSS feed
url = 'http://healthmap.org/rss/ebola-all.rss'
# getting the html
doc <- xmlInternalTreeParse(url)
# collecting the data into a data.frame
output <- data.frame(
title =  xpathSApply(doc, '//item/title', xmlValue),
publication_date = xpathSApply(doc, '//item/', xmlValue),
source_url = xpathSApply(doc, '//item/source/@url', xmlValue),
author = xpathSApply(doc, '//item/author', xmlValue),
country = xpathSApply(doc, '//item/category[@domain="location"]', xmlValue),
latitude = xpathSApply(doc, '//item/geo:lat', xmlValue),
longitude = xpathSApply(doc, '//item/geo:lon', xmlValue),
description = xpathSApply(doc, '//item/description', xmlValue)
)
# returning results
cat('-------------------------------\n')
cat('Done!\n')
cat('-------------------------------\n')
return(output)
}
healthMapData <- scrapeCDCData()
healthMapData <- scrapeHealthMap()
url = 'http://healthmap.org/rss/ebola-all.rss'
doc <- xmlInternalTreeParse(url)
title = xpathSApply(doc, '//item/title', xmlValue)
title
publication_date = xpathSApply(doc, '//item/', xmlValue)
xpathSApply(doc, '//item/')
xpathSApply(doc, '//item')
# Function that fetches the data available
# in HealthMap's website and transforms
# the results into a data table.
scrapeHealthMap <- function() {
cat('----------------------------------------\n')
cat("Collecting the table from HealthMap.\n")
cat('----------------------------------------\n')
# HealthMap RSS feed
url = 'http://healthmap.org/rss/ebola-all.rss'
# getting the html
doc <- xmlInternalTreeParse(url)
# collecting the data into a data.frame
output <- data.frame(
title = xpathSApply(doc, '//item/title', xmlValue),
publication_date = xpathSApply(doc, '//item/pubDate', xmlValue),
source_url = xpathSApply(doc, '//item/source/@url', xmlValue),
author = xpathSApply(doc, '//item/author', xmlValue),
country = xpathSApply(doc, '//item/category[@domain="location"]', xmlValue),
latitude = xpathSApply(doc, '//item/geo:lat', xmlValue),
longitude = xpathSApply(doc, '//item/geo:lon', xmlValue),
description = xpathSApply(doc, '//item/description', xmlValue)
)
# returning results
cat('-------------------------------\n')
cat('Done!\n')
cat('-------------------------------\n')
return(output)
}
healthMapData <- scrapeHealthMap()
xpathSApply(doc, '//item/source/@url', xmlValue)
xpathSApply(doc, '//item/source/@url')
xpathSApply(doc, '//item/source')
xpathSApply(doc, '//item/source[@url]')
xpathSApply(doc, '//item/source[@url]/@url')
xpathSApply(doc, '//item/source[@url]/@url', xmlAttribute)
xpathSApply(doc, '//item/source[@url]/@url', xmlAttributes)
xpathSApply(doc, '//item/source[@url]/@url', xmlValue)
?xmlAttributes
??xmlAttributes
xpathSApply(doc, '//item/source[@url]/@url', xmlAttrs)
xpathSApply(doc, '//item/source[@url]', xmlAttrs)
xpathSApply(doc, '//item/source', xmlAttrs)
xpathSApply(doc, '//item/source')
xpathSApply(doc, '//item/source[@url]')
xpathSApply(doc, '//item/source/[@url]')
xpathSApply(doc, '//item/source/@url')
xpathSApply(doc, '//item/source/@url', xmlValue)
xpathSApply(doc, '//item/source/@url', XMLAttributeValue)
xpathSApply(doc, '//item/source/@url')
class(xpathSApply(doc, '//item/source/@url)')
)
class(xpathSApply(doc, '//item/source/@url')
)
xpathSApply(doc, '//item/source/@url')
xpathSApply(doc, '//item/source/@url')[1]
xpathSApply(doc, '//item/source/@url')$url
xpathSApply(doc, '//item/source/@url')
xpathSApply(doc, '//item/source/@url', xmlGetAttr)
xpathSApply(doc, '//item/source', xmlGetAttr)
xpathSApply(doc, '//item/source', xmlGetAttr, 'url')
# Function that fetches the data available
# in HealthMap's website and transforms
# the results into a data table.
scrapeHealthMap <- function() {
cat('----------------------------------------\n')
cat("Collecting the table from HealthMap.\n")
cat('----------------------------------------\n')
# HealthMap RSS feed
url = 'http://healthmap.org/rss/ebola-all.rss'
# getting the html
doc <- xmlInternalTreeParse(url)
# collecting the data into a data.frame
output <- data.frame(
title = xpathSApply(doc, '//item/title', xmlValue),
publication_date = xpathSApply(doc, '//item/pubDate', xmlValue),
source_url = xpathSApply(doc, '//item/source', xmlGetAttr, 'url'),
author = xpathSApply(doc, '//item/author', xmlValue),
country = xpathSApply(doc, '//item/category[@domain="location"]', xmlValue),
latitude = xpathSApply(doc, '//item/geo:lat', xmlValue),
longitude = xpathSApply(doc, '//item/geo:lon', xmlValue),
description = xpathSApply(doc, '//item/description', xmlValue)
)
# returning results
cat('-------------------------------\n')
cat('Done!\n')
cat('-------------------------------\n')
return(output)
}
# running
healthMapData <- scrapeHealthMap()
xpathSApply(doc, '//item/author', xmlValue)
xpathSApply(doc, '//item/category[@domain="location"]', xmlValue)
xpathSApply(doc, '//item/geo:lat', xmlValue)
xpathSApply(doc, '//item/geo:lon', xmlValue)
xpathSApply(doc, '//item/geo:long', xmlValue)
xpathSApply(doc, '//item/description', xmlValue)
# Function that fetches the data available
# in HealthMap's website and transforms
# the results into a data table.
scrapeHealthMap <- function() {
cat('----------------------------------------\n')
cat("Collecting the table from HealthMap.\n")
cat('----------------------------------------\n')
# HealthMap RSS feed
url = 'http://healthmap.org/rss/ebola-all.rss'
# getting the html
doc <- xmlInternalTreeParse(url)
# collecting the data into a data.frame
output <- data.frame(
title = xpathSApply(doc, '//item/title', xmlValue),
publication_date = xpathSApply(doc, '//item/pubDate', xmlValue),
source_url = xpathSApply(doc, '//item/source', xmlGetAttr, 'url'),
author = xpathSApply(doc, '//item/author', xmlValue),
country = xpathSApply(doc, '//item/category[@domain="location"]', xmlValue),
latitude = xpathSApply(doc, '//item/geo:lat', xmlValue),
longitude = xpathSApply(doc, '//item/geo:long', xmlValue),
description = xpathSApply(doc, '//item/description', xmlValue)
)
# returning results
cat('-------------------------------\n')
cat('Done!\n')
cat('-------------------------------\n')
return(output)
}
# running
healthMapData <- scrapeHealthMap()
View(healthMapData)
setwd("~/Documents/Programming/progress-visuals")
m <- read.csv('data/mailchimp.csv')
t <- read.csv('data/twitter.csv')
r <- read.csv('data/repository.csv')
head(m)
View(mailc)
View(m)
View(t)
as.Date(t$Week, "%d/%m/%Y")
as.Date(t$Week, "%m/%d/%Y")
t$Week <- as.Date(t$Week, "%m/%d/%Y")
View(R)
View(r)
melt(r, id = 'Date_and_Time')
library(reshape2)
library(ggplot2)
melt(r, id = 'Date_and_Time')
r <- melt(r, id = 'Date_and_Time')
View(r)
as.Date(r$Date_and_Time)
r$Date_and_Time <- as.Date(r$Date_and_Time)
ggplot(r) + theme_bw() +
geom_lint(aes(Date_and_Time, value, color = variable))
ggplot(r) + theme_bw() +
geom_line(aes(Date_and_Time, value, color = variable))
datasets <- r[variable = 'Number_of_Datasets',]
datasets <- r[r$variable = 'Number_of_Datasets',]
datasets <- r[r$variable == 'Number_of_Datasets',]
users_orgs <- r[r$variable == 'Number_of_Organizations' | r$variable = 'Number_of_Users', ]
users_orgs <- r[r$variable == 'Number_of_Organizations' | r$variable == 'Number_of_Users', ]
View(users_orgs)
ggplot(datasets) + theme_bw() +
geom_line(aes(Date_and_Time, value, color = variable))
ggplot(datasets) + theme_bw() +
geom_line(aes(Date_and_Time, value), color = "#1EBFB3", size = 1.3)
ggplot(datasets) + theme_bw() +
geom_line(aes(Date_and_Time, value), color = "#1EBFB3", size = 1.3)
ggplot(users_orgs) + theme_bw() +
geom_line(aes(Date_and_Time, value, color = variable), size = 1.3)
# Number of Datasets
dplot <- ggplot(datasets) + theme_bw() +
geom_line(aes(Date_and_Time, value), color = "#1EBFB3", size = 1.3)
ggsave('plot/number-of-datasets.pdf', dplot, width = 200, height = 80, units = 'mm')
ggsave('plot/number-of-datasets.pdf', dplot, width = 400, height = 160, units = 'mm')
# Number of Organizations and Users
oplot <- ggplot(users_orgs) + theme_bw() +
geom_line(aes(Date_and_Time, value, color = variable), size = 1.3)
ggsave('plot/number-of-organizations-users', oplot, width = 400, height = 160, units = 'mm')
ggsave('plot/number-of-organizations-users.pdf', oplot, width = 400, height = 160, units = 'mm')
names(v)
name(datasets)
names(datasets)
max(datasets$value)
max(datasets$Date_and_Time)
datasets[datasets$Date_and_Time == as.Date('2014-10-15'),]
users_orgs[users_orgs$Date_and_Time == as.Date('2014-10-15'),]
View(t)
names(t)
ggplot(t) + theme_bw() +
geom_line(aes(Week, Followers), size = 1.3)
tplot <- ggplot(t) + theme_bw() +
geom_line(aes(Week, Followers), size = 1.3)
ggsave('plot/number-of-followers.pdf', tplot, width = 400, height = 160, units = 'mm')
max(t$Week)
t[t$Week == as.Date('2014-10-13'), ]
